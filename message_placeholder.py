
'''
Reading the query here from chat_history.txt

MessagesPlaceholder : to maintain the context of past interactions between Human and System messages
Basically whatever MessagesPlaceholder is used to store/maintain/refer to all the past interactions to 
maintain the context of the conversation. In a way, whatever reply is being generated by AI system will be 
in coherence with the past interactions.

'''
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage

# chat template
chat_template = ChatPromptTemplate([
    ('system','You are a helpful customer support agent'),   # defining a system message
    MessagesPlaceholder(variable_name='chat_history'),
    ('human','{query}')
])

chat_history = []

# load chat history
with open('chat_history.txt') as f:
    chat_history.extend(f.readlines())

print(chat_history)

# create prompt
prompt = chat_template.invoke({'chat_history':chat_history, 'query':HumanMessage(content='Where is my refund ?')})

print(prompt)

# in the output you can see, the last human message : Where is my refund ? 
# before that you can see , the model has generated the entire context history to refer to the past interactions