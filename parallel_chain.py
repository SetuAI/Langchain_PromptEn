'''
User gives the text which contains information about a topic in detail.
We will take the document and generate 2 things : 1.notes and 2. quiz
then we will combine both and show to the user
To build this, we need to use parallel chain.

Unlike in sequential chain, where tasks happen sequentially, in parallel chain, tasks happen in parallel.

So we will do this task parallely.

Send the text to model 1(say GPT )
This will generate notes

At the same time, parallely, we will generate quiz with help of that text to model 2 (claude)

And then send these 2 two tasks to a 3rd model (gemini)
Then , merge them and display in the output

'''

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
load_dotenv()
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.schema.runnable import RunnableParallel #to create parallel chain we need RunnableParallel
# with RunnableParallel we can run multiple chain in parallel

# we will be using 2 models here : gpt and gemini
model1 = ChatOpenAI()

model2 = ChatGoogleGenerativeAI(model="gemini-2.0-flash-001")

# design 1st prompt : i am giving you a text, generate short and simple notes from it
prompt1 = PromptTemplate(
    template='Generate short and simple notes from the following text \n {text}',
    input_variables=['text']
)


# design 2nd prompt : i am giving you a text, generate quiz from it
prompt2 = PromptTemplate(
    template='Generate 5 short question answers from the following text \n {text}',
    input_variables=['text']
)

# merging prompt : i am giving you notes and quiz, merge them into a single document
prompt3 = PromptTemplate(
    template='Merge the provided notes and quiz into a single document \n notes -> {notes} and quiz -> {quiz}',
    input_variables=['notes', 'quiz']
)

# create parser
parser = StrOutputParser()

# we will develop the chain here in 2 parts : parallel and merge

# creating parallel chain here
# inside RunnableParallel you can define multiple chains at once
parallel_chain = RunnableParallel({ 
    'notes': prompt1 | model1 | parser, # 1st chain
    'quiz': prompt2 | model2 | parser   # 2nd chain
})

merge_chain = prompt3 | model1 | parser # this is a sequential chain pattern if you look at it

# we create a final chain where we connect parallel chain and merge chain
chain = parallel_chain | merge_chain

text = """
Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.

The advantages of support vector machines are:

Effective in high dimensional spaces.

Still effective in cases where number of dimensions is greater than the number of samples.

Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.

Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.

The disadvantages of support vector machines include:

If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.

SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).

The support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) with dtype=float64.
"""

result = chain.invoke({'text':text})

print(result)

chain.get_graph().print_ascii()


'''
So you can check in the output : we get the notes and quiz generated by 2 different models

After this we will be studying conditional chains : conditional_chain.py
'''